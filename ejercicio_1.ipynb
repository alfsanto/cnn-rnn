{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 16:49:53.489440: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-21 16:49:53.722560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-21 16:49:53.722582: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-21 16:49:53.813594: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-21 16:49:54.640695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-21 16:49:54.640740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-21 16:49:54.640746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv1D, Flatten, Dropout, BatchNormalization, MaxPooling2D, LSTM, GRU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tenemos un problema de clasificación de objetos donde tenemos 5000 imágenes de 28x28 en color. Para cada objeto tenemos una etiqueta numérica con valores de [0-19] (20 clases de objetos distintas). Propon un modelo teniendo en cuenta lo que has aprendido en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMENTARIOS__ \n",
    "\n",
    "* Implemento un modelo muy simple. De esta manera me servirá para ver como mejora según le vaya añadiendo cosas en los siguiente ejercicios.\n",
    "\n",
    "* Probablemente sería mejor añadir una segunda capa Conv2D\n",
    "\n",
    "* Añado capa de maxpool para disminuir el número de parámetros ya que no tengo muchos datos. Aunque, en realidad, tenemos muchos datos 26 * 26 * 3 * 5000 = 10.140.000\n",
    "\n",
    "* La primera capa Dense sirve para seleccionar los patrones más relevantes de todos los que selecciona la capa Conv2d y la segunda para calcular las probabilidades de cada una de las 20 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 33)                178497    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                680       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,073\n",
      "Trainable params: 180,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, 3, input_shape=(28, 28, 3), activation='relu'))\n",
    "model_1.add(MaxPooling2D((2,2)))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(33, activation='relu'))\n",
    "model_1.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='categorical_cross_entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tenemos 500 datos de series temporales de un activo financiero, cada dato tiene una longitud de 7. Las salidas son las predicciones para el instante temporal siguiente. Escribe un trozo de código que sirva para definir un modelo en Keras que tenga al menos dos capas LSTM, una capa GRU y una densa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__COMENTARIOS:__ \n",
    "\n",
    "* El modelo tiene solo 1229 parámetros ya que tenemos muy pocos datos\n",
    "\n",
    "* Es fundamental el orden de las distintas capas:\n",
    "\n",
    "    * Las dos primeras capas son many to many y la tercera es many to one\n",
    "\n",
    "    * Las capas LSTM tienen memoria corta y larga por lo que funcionan bien en configuraciones many to many\n",
    "\n",
    "    * Las capas GRU solo tienen memoria a largo y encajan más en las configuraciones many to one\n",
    "    \n",
    "    * Por esto, ponemos primero las capas LSTM y luego la GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 500, 8)            512       \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 500, 8)            544       \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 4)                 168       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,229\n",
      "Trainable params: 1,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_datos = 500\n",
    "datos_length = 7\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(LSTM(8, input_shape=(n_datos, datos_length), return_sequences=True))\n",
    "model_2.add(LSTM(8, return_sequences=True))\n",
    "model_2.add(GRU(4))\n",
    "model_2.add(Dense(1))\n",
    "\n",
    "model_2.compile(optimizer='adam',loss='mae')\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tenemos 50000 datos de series temporales de 10 activos financieros de longitud 13, i.e. (50000, 13, 10). La salida son las 4 posibles fases del investment clock (reflation, recovery, overheat, y stagflation) para el instante temporal siguiente. Escribe un trozo de código que sirva para definir un modelo en Keras que combine al menos una capa LSTM, dos convolucionales y una densa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comentarios:__\n",
    "\n",
    "* Pongo primero las capas convolucionales ya que busca patrones importantes y no pierde la noción temporal y luego ya uso las LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 11, 64)            1984      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 9, 128)            24704     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                20608     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,428\n",
      "Trainable params: 47,428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Conv1D(64, 3, input_shape=(13, 10)))\n",
    "model_3.add(Conv1D(128, 3))\n",
    "model_3.add(LSTM(32))\n",
    "model_3.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model_3.compile(optimizer= Adam(),\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "model_3.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9149f39d3a747901e90d83778310fdb90185cf9546bfe11a7f88a5b0e75397d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
